---
title: "Step 4 - Minu"
author: "Minu Pabbathi, Ziqian Zhao, Paul Zhang"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F,
                      message = F,
                      warning = F)

# load packages
library(glmnet)
library(ggplot2)
library(pROC)

# load dataset
heart_disease_data <- read.csv("~/Documents/GitHub/s24-pstat126-project/dataset/heart_disease_data_1.csv")
heart_disease_data$sex<-as.factor(heart_disease_data$sex)
heart_disease_data$cp<-as.factor(heart_disease_data$cp)
heart_disease_data$fbs<-as.factor(heart_disease_data$fbs)
heart_disease_data$restecg<-as.factor(heart_disease_data$restecg)
heart_disease_data$exang<-as.factor(heart_disease_data$exang)
heart_disease_data$slope<-as.factor(heart_disease_data$slope)
heart_disease_data$target<-as.factor(heart_disease_data$target)

# split data into training and testing
set.seed(7)
train_idx <- sample(1:nrow(heart_disease_data), 0.8 * nrow(heart_disease_data)) 
train_data <- heart_disease_data[train_idx, ] 
test_data <- heart_disease_data[-train_idx, ]
```

# Introduction

This data set dates from 1988 and consists of four databases: Cleveland, Hungary, Switzerland, and Long Beach V. It contains information about patients and risk factors for heart disease as well as whether or not they eventually end up developing heart disease. For the sake of convenience, we have randomly chosen 500 observations from the original data set. In this step, we are going to execute LASSO and ridge regression to find alternative models, and finally use logistic regression to determine the probability of a patient having heart disease.


# Shrinkage Methods
 
## LASSO Regression

LASSO regression is a type of linear regression that is used for shrinkage and variable selection. A penalty term equivalent to the absolute value of the coefficients times a tuning parameter $\lambda$ is added to discourage large values of $\beta$. As a result, some coefficients are shrunk to 0, making LASSO a useful tool for variable selection. Thus, finding an optimal $\lambda$ is crucial to maintaining a balance between shrinkage and a usable model. Additionally, by introducing bias through the penalty term, LASSO regression can decrease the variance of the coefficient estimates, leading to a lower out-of-sample MSE and better generalization.

Here, $\lambda$ is selected by testing a grid of potential values and then conducting 10-fold cross validation to determine which value minimizes the test MSE. Fig. __ plots the test MSE against potential $\lambda$ values

```{r}
y <- train_data$thalach
x <- scale(data.matrix(train_data[ , -8]))
set.seed(1)
lasso_model <- cv.glmnet(x, y, alpha = 1)
lambda_lasso <- lasso_model$lambda.min
print(paste("Best lambda:", lambda_lasso))
```

```{r, fig.cap = "MSE vs. Lambda"}
# plot mse vs. lambda
par(mar = c(7, 4, 2.2, 0.5))
plot(lasso_model, cex = 0.8)
```

### Final LASSO Model

Using the calculated optimal $\lambda$, we fit the final model:

```{r}
# choose best model
best_lasso_model <- glmnet(x, y, alpha = 1, lambda = lambda_lasso)
coef(best_lasso_model)
```

### Predictions

Using the test data, the predicted values plotted against the observed values follow a near linear trend, indicating the model is helpful for prediction.

```{r, fig.cap = "Plotting predicted values using LASSO regression against observed values"}
# making predictions
new_x <- scale(data.matrix(test_data[ , -8]))
y_pred_lasso <- predict(best_lasso_model, s = lambda_lasso, newx = new_x)
plot(y_pred_lasso, test_data$thalach, xlab = "Predicted Values", ylab = "Observed Values")
abline(1, 1)
```


# Innovation

## Method Justification

To explore further models, we decided to use logistic regression since we were interested in seeing how the variables can be used to predict heart disease, or the `target` variable. Since heart disease is a binary variable, OLS, ridge, and LASSO cannot be used since the response variable in these cases must be continuous.

## Variable Selection

First, we used LASSO to determine which variables to include in the model. 

```{r}
# variable selection using lasso regression
x_log <- model.matrix(target ~ ., data = train_data)[, -14]
y_log <- train_data$target

# Fit lasso model using cross-validation to find optimal lambda
lasso_model_log <- cv.glmnet(x_log, y_log, family = "binomial", alpha = 1)

# Optimal lambda
set.seed(2)
lambda_optimal_log <- lasso_model_log$lambda.min
print(paste("Best lambda:", lambda_optimal_log))

# Coefficients at optimal lambda
coef(lasso_model_log, s = lambda_optimal_log)
```

## Fitting Logistic Model

Based on the results from the LASSO regression, we fit a logistic model using the non-zero coefficients.

```{r}
log_model <- glm(target ~ age + sex + cp + trestbps + fbs + restecg + thalach + exang + slope + ca + thal, data = train_data, family = binomial)
summary(log_model)
```

## ROC Curve

A tool to visualize logistic regression is a ROC (Receiver Operating Characteristic) curve, in which the true positive rate (sensitivity) is plotted against the false positive rate (1 - specificity) at different threshold values. The closer the ROC curve is to the top-left corner, the better the model is at distinguishing between positive and negative classes. A model with no discriminative power will have an ROC curve along the diagonal line, essentially equivalent to random guessing. As can be seen in Fig. __, the ROC curve is relatively close to the top-left corner, indicating that the model has high sensitivity and high specificity.

```{r, fig.cap = "ROC Curve for logisitic model"}
predicted_prob <- predict(log_model, type = "response")
roc_curve <- roc(train_data$target, predicted_prob)
plot(roc_curve, main = "ROC Curve")
```

## AUC

The AUC, or area under the curve, is a measure of how well the model is able to discriminate between positive and negative cases. The AUC ranges from 0 to 1, with the following interpretations:

 - < 0.5: No discriminative power (equivalent to random guessing).
 - 0.5 - 0.7: Poor discrimination.
 - 0.7 - 0.8: Acceptable discrimination.
 - 0.8 - 0.9: Excellent discrimination.
 - \> 0.9: Outstanding discrimination.

```{r}
print(paste("AUC:", auc(roc_curve)))
```

Since the AUC is above 0.9, we can conclude that our model is highly accurate at distinguishing between cases.

## Optimal Threshold Value

Based on the ROC curve, we can determine the optimal threshold value, which is the value that maximizes the distance from the diagonal line (representing random chance) or maximizes the area under the ROC curve (AUC). If the predicted probability is less than the threshold, then the response can be classified as 0, or no heart disease. If the predicted probability is greater than threshold, then the response can be classified as 1, or having heart disease.

```{r}
optimal_cutoff <- coords(roc_curve, "best", ret = "threshold")
print(paste("Optimal threshold value:", optimal_cutoff))
```


