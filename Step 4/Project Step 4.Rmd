---
title: "Project Step 4"
author: "Minu Pabbathi, Ziqian Zhao, Paul Zhang"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F,
                      warning = F,
                      message = F,
                      fig.width = 5,
                      fig.height = 4)
# load packages
library(glmnet)
library(ggplot2)
library(pROC)

# load dataset
heart_disease_data <- read.csv("~/Documents/GitHub/s24-pstat126-project/dataset/heart_disease_data_1.csv")
heart_disease_data$sex<-as.factor(heart_disease_data$sex)
heart_disease_data$cp<-as.factor(heart_disease_data$cp)
heart_disease_data$fbs<-as.factor(heart_disease_data$fbs)
heart_disease_data$restecg<-as.factor(heart_disease_data$restecg)
heart_disease_data$exang<-as.factor(heart_disease_data$exang)
heart_disease_data$slope<-as.factor(heart_disease_data$slope)
heart_disease_data$target<-as.factor(heart_disease_data$target)

# split data into training and testing
set.seed(7)
train_idx <- sample(1:nrow(heart_disease_data), 0.8 * nrow(heart_disease_data)) 
train_data <- heart_disease_data[train_idx, ] 
test_data <- heart_disease_data[-train_idx, ]

# Function to scale numeric columns
scale_numeric <- function(df) {
  for (col in names(df)) {
    if (is.numeric(df[[col]])) {
      df[[col]] <- scale(df[[col]])
    }
  }
  return(df)
}
y <- train_data$thalach
sacled_train_data <- scale_numeric(train_data[ ,-8])
x <- model.matrix(y~.,data = sacled_train_data)

scaled_new_x <- scale_numeric(test_data[ ,-8])
new_x <- model.matrix(test_data$thalach~.,scaled_new_x)
```

# Introduction

This data set dates from 1988 and consists of four databases: Cleveland, Hungary, Switzerland, and Long Beach V. It contains information about patients and risk factors for heart disease as well as whether or not they eventually end up developing heart disease. For the sake of convenience, we have randomly chosen 500 observations from the original data set. In this step, we are going to execute LASSO and ridge regression to find alternative models, and finally use logistic regression to determine the probability of a patient having heart disease.

# Shrinkage Methods
 
## LASSO Regression

LASSO regression is a type of linear regression that is used for shrinkage and variable selection. A penalty term equivalent to the absolute value of the coefficients times a tuning parameter $\lambda$ is added to discourage large values of $\beta$. As a result, some coefficients are shrunk to 0, making LASSO a useful tool for variable selection. Thus, finding an optimal $\lambda$ is crucial to maintaining a balance between shrinkage and a usable model. Additionally, by introducing bias through the penalty term, LASSO regression can decrease the variance of the coefficient estimates, leading to a lower out-of-sample MSE and better generalization.

Here, $\lambda$ is selected by testing a grid of potential values and then conducting 10-fold cross validation to determine which value minimizes the test MSE. Fig. 1 plots the test MSE against potential $\lambda$ values

```{r}
set.seed(1)
lasso_model <- cv.glmnet(x, y, alpha = 1)
lambda_lasso <- lasso_model$lambda.min
print(paste("Best lambda:", lambda_lasso))
```

```{r, fig.cap = "MSE vs. Lambda"}
# plot mse vs. lambda
par(mar = c(7, 4, 2.2, 0.5))
plot(lasso_model, cex = 0.8)
```

### Final LASSO Model

Using the calculated optimal $\lambda$, we fit the final model:

$$
\begin{aligned}
\text{max heart rate}_i = 143.61-6.99\cdot age_i&+8.89\cdot1\{cp_i=1\}+3.87\cdot1\{cp_i=2\}
 +13.43\cdot1\{cp_i=3\} + 1.67 \cdot trestbps_i\\
 &-2.14\cdot1\{restecg_i=1\}-7.70\cdot1\{restecg_i=2\}-8.47\cdot1\{exang_i = 1\}\\
 &-0.81\cdot oldpeak_i-1.78\cdot1\{slope_i=1\}+9.98\cdot1\{slope_i=2\}-0.36\cdot ca_i\\
 & + 0.22 \cdot chol_i +0.59\cdot thal_i+6.29\cdot1\{target_i=1\}
\end{aligned}
$$

```{r, results = "hide"}
# choose best model
best_lasso_model <- glmnet(x, y, alpha = 1, lambda = lambda_lasso)
coef(best_lasso_model)
```

### Predictions

Using the test data, the predicted values plotted against the observed values follow a near linear trend, indicating the model is helpful for prediction.

```{r, fig.cap = "Plotting predicted values using LASSO regression against observed values"}
# making predictions
y_pred_lasso <- predict(best_lasso_model, s = lambda_lasso, newx = new_x)
plot(y_pred_lasso, test_data$thalach, xlab = "Predicted Values", ylab = "Observed Values")
abline(1, 1)
```


## Ridge Regression

Ridge model is a method of estimating the coefficients of multi-variable linear regression.Different from Ordinary Least Square(OLS) method, Ridge regression, including a penalty term, provides a trade-off between variance and bias, which are the two criteria for MSE what we want to minimize.

Here, we fit a Ridge regression with the optimal lambda found through cross validation 

```{r}
ridge_model <- cv.glmnet(x, y, alpha = 0)
lambda_ridge <- ridge_model$lambda.min
print(paste("By cross validation between 10 folds, the optimal lambda is", round(lambda_ridge,4)))
```

```{r,fig.cap="MSE vs. Lambda"}
par(mar = c(7, 4, 2.2, 0.5))
plot(ridge_model, cex = 0.8)
abline(v = log(lambda_ridge), col = "purple", lty = 2)
```

Fig. 3 visualized how MSE change with the regularization parameter $\lambda$. As our goal is to minimize MSE, we locate the $log(\lambda)$ correspond to the smallest MSE, which shown by the purple line and select the lambda as the regularization factor. 

```{r,include=FALSE}
# choose best model
best_ridge_model <- glmnet(x, y, alpha = 0, lambda = lambda_ridge)
coef(best_ridge_model)
```

We then fit the model with the penalty term and obtain the estimated coefficients. In terms of variable selection, more variables are considered significant than forward step-wise selection (the method used previous).
Specifically, `oldpeak`,`ca`, and `thal` are also considered as significant (the |coefficient| > 0.5). The final model is

$$
\begin{aligned}
\text{max heart rate}_i = 146.21-6.34\cdot age_i&+8.66\cdot1\{cp_i=1\}+4.03\cdot1\{cp_i=2\}
 +13.03\cdot1\{cp_i=3\} + 1.60 \cdot trestbps_i\\
 &-2.22\cdot1\{restecg_i=1\}-10.13\cdot1\{restecg_i=2\}-8.12\cdot1\{exang_i = 1\}\\
 &-1.39\cdot oldpeak_i-4.33\cdot1\{slope_i=1\}+7.37\cdot1\{slope_i=2\}-0.68\cdot ca_i\\
 &+0.83\cdot thal_i+6.12\cdot1\{target_i=1\}
\end{aligned}
$$

### Making Predictions
```{r, fig.cap = "Ridge Predicted Values vs. Observed Values"}
y_pred_ridge <- predict(best_ridge_model, s = lambda_ridge, newx = new_x)
plot(test_data$thalach, y_pred_ridge, ylab = "Predicted Values", xlab = "Observed Values")
abline(1, 1)
```

Fig. 4 is predicted value vs. observed value, which visualizes the accuracy of the prediction with ridge regression. The dots, as expected, are spread around y=x, which indicates that the ridge regression, though with some outliers, provided a relatively good prediction. 


```{r}
fit <- lm(thalach ~ slope + age + cp + exang + target + trestbps + restecg, data = train_data)
y_pred_mlr <- predict(fit, newdata = test_data)
```


```{r}
y_pred_lasso <- as.data.frame(y_pred_lasso)
y_pred_ridge <- as.data.frame(y_pred_ridge)
y_pred_mlr <- as.data.frame(y_pred_mlr)
y_observed_og <- test_data$thalach

colnames(y_pred_lasso) <- c("values")
colnames(y_pred_ridge) <- c("values")
colnames(y_pred_mlr) <- c("values")

y_pred_lasso$Source <- rep("Lasso", length(y_pred_lasso))
y_pred_ridge$Source <- rep("Ridge", length(y_pred_ridge))
y_pred_mlr$Source <- rep("MLR", length(y_pred_mlr))

combined_preds_og <- rbind(y_pred_lasso, y_pred_ridge, y_pred_mlr)
y_observed <-rep(y_observed_og, 3)
combined_preds <- cbind(y_observed, combined_preds_og)
```


## Making Combined Plot
```{r,include=FALSE}
combined_plot <- ggplot(combined_preds, aes(x = y_observed, y = values, color = Source)) +
  geom_point() + 
  geom_abline(intercept = 0, slope = 1, color = "black", linetype = "dashed")+
  labs(x = "Observed Values", y = "Predicted Values")
  
```

```{r,fig.cap="Combined Plot"}
combined_plot
```

## Model Comparison
The plot shows that the predictions between three models do not differentiate much. Specifically, the observations of three models, represented by three different colors, located close to each other along the line $y=x$.

Specifically, dots of LASSO (red) and Ridge(blue) are closely located together and the small deviation could be caused by differences between the penalty term (i.e. $\lambda$).

The dots of OLS(green) deviated relatively more from the others which could be a result of different predictor selection. Specifically, lasso and ridge regression consider three more variables significant. However, the deviation is not significant, so it is reasonable to conclude that predictor are consistently selected.

|Predictors| Lasso | Ridge  | MLR |
|----------|----------|----------|-----------|
| Age | -6.99 | -6.34 | 0 |
| Sex = 1 | 0 | -0.29 | 0 |
| Chest Pain type =1 | 8.89 | 8.66 | 10.56  |
| Chest Pain type=2 | 3.87 | 4.03 | 5.17 |
| Chest Pain type=3 | 13.43 | 13.03 | 15.11 |
| Rest bps| 1.67 | 1.60 | 0.12 |
| Serum Cholesterol| 0.22 | 0.31 |  0 |
| Fasting blood sugar =1| 0 | 0.31 |  0 |
| Rest ecg=1| -2.14 | -2.22 | -3.18 |
| Rest ecg=2| -7.69 | -10.12 |  -12.76 |
| Exercise angina=1| -8.47 | -8.12 | -8.35 |
| oldpeak| -0.81 | -1.39 | 0 |
| ST slpoe =1| -7.18 | -4.33 | -1.16 |
| ST slope =2| 9.98 | 7.37 | 11.27 |
| Target =1| 6.29 | 6.12 | 6.43 |


From the table above, which shows the estimated coefficients from three regression methods, it further convinced that the coefficients are inherently and similarly estimated.

## Conclusion

After applying RR and LASSO to our model, we have found similarly selected predictors, and also the predictions are generally promising compared to observed data. When compared with the model we had from MLR, several predictors are reconsidered and we still have relatively consistent predicted result. It is also noteworthy that when looking at the superimposed graph, we had outliners that distributing similarly across three methods, which indicating that further steps are needed to take care of them.

# Innovation

Logistic regression is used to predict the outcome of a binary variable, for example 0 or 1. Suppose the probability of 1 occurs is p and the probability of 1 does not occur is 1-p, then the ratio of 1 occurring vs. 1 not-occurring is simply $\frac{1}{1-p}$. 

Since we then need a linear regression to estimate the coefficient, we then apply log map the probability to real number for linear regression, that is $$Logit(p) = log(\frac{p}{1-p})$$

Apply $logit(p)$ as the new response and fit a linear model with the predictor variables. 

$$
Logit(p) = \beta_0 + \beta_1x_1+\beta_2x_2+\cdots+\beta_nx_n
$$

Then we inverse the logit to get $p$, namely, 
$$
p = \frac{1}{1+e^{-(\beta_0 + \beta_1x_1+\beta_2x_2+\cdots+\beta_nx_n)}}
$$

## Technical Conditions

1. The response variable is binary. This fits our model that the response is the target variable, which indicates whether the patient have heart disease.

2. The model should have minimal multicollinearity. The LASSO regression is removing predictors that are having high correlations. 

3. Sufficient sample size and independent observation. Our dataset is large and the patients conditions are independent.

4. There shouldn't be prefect separation. We don't have some predictors that can precisely predict the outcome.

5. There shouldn't be highly influential outliners. For this one we didn't particularly remove the outliners.

## Method Justification

To explore further models, we decided to use logistic regression since we were interested in seeing how the variables can be used to predict heart disease, or the `target` variable. Since heart disease is a binary variable, OLS, ridge, and LASSO cannot be used since the response variable in these cases must be continuous.

## Variable Selection

First, we used LASSO to determine which variables to include in the model. 

```{r}
# variable selection using lasso regression
x_log <- model.matrix(target ~ ., data = train_data)[, -14]
y_log <- train_data$target

# Fit lasso model using cross-validation to find optimal lambda
lasso_model_log <- cv.glmnet(x_log, y_log, family = "binomial", alpha = 1)

# Optimal lambda
set.seed(2)
lambda_optimal_log <- lasso_model_log$lambda.min
print(paste("Best lambda:", lambda_optimal_log))

# Coefficients at optimal lambda
coef(lasso_model_log, s = lambda_optimal_log)
```

## Fitting Logistic Model

Based on the results from the LASSO regression, we fit a logistic model using the non-zero coefficients.

```{r}
log_model <- glm(target ~ age + sex + cp + trestbps + fbs + restecg + thalach + exang + slope + ca + thal, data = train_data, family = binomial)
summary(log_model)
```

## ROC Curve

A tool to visualize logistic regression is a ROC (Receiver Operating Characteristic) curve, in which the true positive rate (sensitivity) is plotted against the false positive rate (1 - specificity) at different threshold values. The closer the ROC curve is to the top-left corner, the better the model is at distinguishing between positive and negative classes. A model with no discriminative power will have an ROC curve along the diagonal line, essentially equivalent to random guessing. As can be seen in Fig. 6, the ROC curve is relatively close to the top-left corner, indicating that the model has high sensitivity and high specificity.

```{r, fig.cap = "ROC Curve for logisitic model"}
predicted_prob <- predict(log_model, type = "response")
roc_curve <- roc(train_data$target, predicted_prob)
plot(roc_curve, main = "ROC Curve")
```

## AUC

The AUC, or area under the curve, is a measure of how well the model is able to discriminate between positive and negative cases. The AUC ranges from 0 to 1, with the following interpretations:

 - < 0.5: No discriminative power (equivalent to random guessing).
 - 0.5 - 0.7: Poor discrimination.
 - 0.7 - 0.8: Acceptable discrimination.
 - 0.8 - 0.9: Excellent discrimination.
 - \> 0.9: Outstanding discrimination.

```{r}
print(paste("AUC:", auc(roc_curve)))
```

Since the AUC is above 0.9, we can conclude that our model is highly accurate at distinguishing between cases.

## Optimal Threshold Value

Based on the ROC curve, we can determine the optimal threshold value, which is the value that maximizes the distance from the diagonal line (representing random chance) or maximizes the area under the ROC curve (AUC). If the predicted probability is less than the threshold, then the response can be classified as 0, or no heart disease. If the predicted probability is greater than threshold, then the response can be classified as 1, or having heart disease.

```{r}
optimal_cutoff <- coords(roc_curve, "best", ret = "threshold")
print(paste("Optimal threshold value:", optimal_cutoff))
```

